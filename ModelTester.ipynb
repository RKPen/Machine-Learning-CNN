{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tf_keras import layers \n",
    "\n",
    "# Use Keras 2.\n",
    "version_fn = getattr(tf.keras, \"version\", None)\n",
    "if version_fn and version_fn().startswith(\"3.\"):\n",
    "  import tf_keras as keras\n",
    "else:\n",
    "  keras = tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download: *\n",
      "Downloaded: variables.data-00000-of-00001\n",
      "Downloaded: variables.index\n",
      "Downloaded: fingerprint.pb\n",
      "Failed to download: keras_metadata.pb\n",
      "Downloaded: saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the GitHub repository URL\n",
    "github_model_url = \"https://github.com/RKPen/Project/raw/main/exported_model\"\n",
    "\n",
    "# Define the directory where you want to save the model files\n",
    "destination_dir = \"destination_directory\"\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "\n",
    "# Create a variables directory within the destination directory\n",
    "variables_dir = os.path.join(destination_dir, \"variables\")\n",
    "if not os.path.exists(variables_dir):\n",
    "    os.makedirs(variables_dir)\n",
    "\n",
    "# List of model files\n",
    "model_files = [\n",
    "    \"asset/*\",\n",
    "    \"variables/variables.data-00000-of-00001\",\n",
    "    \"variables/variables.index\",\n",
    "    \"fingerprint.pb\",\n",
    "    \"keras_metadata.pb\",\n",
    "    \"saved_model.pb\"\n",
    "]\n",
    "\n",
    "# Download each file in the list\n",
    "for file in model_files:\n",
    "    file_url = f\"{github_model_url}/{file}\"\n",
    "    file_name = file.split(\"/\")[-1]  # Extract file name from the URL\n",
    "    \n",
    "    # Adjust file path for variables files\n",
    "    if \"variables\" in file:\n",
    "        file_path = os.path.join(variables_dir, file.split(\"/\")[-1])\n",
    "    else:\n",
    "        file_path = os.path.join(destination_dir, file_name)\n",
    "\n",
    "    # Download the file\n",
    "    response = requests.get(file_url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Save the file\n",
    "        with open(file_path, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded: {file_name}\")\n",
    "        \n",
    "        # If it's a variables file, remove it from the root directory\n",
    "        if \"variables\" in file:\n",
    "            root_file_path = os.path.join(destination_dir, file.split(\"/\")[-1])\n",
    "            if os.path.exists(root_file_path):\n",
    "                os.remove(root_file_path)\n",
    "                print(f\"Removed from root directory: {file.split('/')[-1]}\")\n",
    "    else:\n",
    "        print(f\"Failed to download: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5131 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'C:\\\\Users\\\\Karim\\\\OneDrive\\\\Documents\\\\UNI\\\\SPRING 24\\\\CMPS 261\\\\Project\\\\Food-Item-Recognition\\\\data'\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess_image(image):\n",
    "    # Preprocess input image using ResNet V2 preprocessing function\n",
    "    return keras.applications.resnet_v2.preprocess_input(image)\n",
    "\n",
    "# Create an ImageDataGenerator for preprocessing images\n",
    "data_generator = keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image\n",
    ")\n",
    "\n",
    "# Load and preprocess training data\n",
    "data_flow = data_generator.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(128, 128),  # Resize images to 128 X 128\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m saved_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdestination_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf_keras\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(saved_model_path)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Iterate over the generator to get predictions batch by batch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data_flow)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_keras' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Initialize empty lists to store predictions and true labels\n",
    "all_predicted_labels = []\n",
    "all_true_labels = []\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "saved_model_path = \"destination_directory\"\n",
    "saved_model = keras.models.load_model(saved_model_path)\n",
    "\n",
    "# Iterate over the generator to get predictions batch by batch\n",
    "for i in range(len(data_flow)):\n",
    "    x_batch, y_batch = data_flow[i]\n",
    "    \n",
    "    # Generate predictions for the current batch\n",
    "    batch_predictions = saved_model.predict(x_batch)\n",
    "    \n",
    "    # Convert predictions to class labels\n",
    "    batch_predicted_labels = np.argmax(batch_predictions, axis=1)\n",
    "    \n",
    "    # Convert true labels to class indices if they are one-hot encoded\n",
    "    if y_batch.shape[1] > 1:\n",
    "        batch_true_labels = np.argmax(y_batch, axis=1)\n",
    "    else:\n",
    "        batch_true_labels = y_batch\n",
    "    \n",
    "    # Accumulate batch predictions and true labels\n",
    "    all_predicted_labels.extend(batch_predicted_labels)\n",
    "    all_true_labels.extend(batch_true_labels)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predicted_labels = np.array(all_predicted_labels)\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "\n",
    "# Generate classification report\n",
    "class_names = list(data_flow.class_indices.keys())\n",
    "print(classification_report(all_true_labels, all_predicted_labels, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
